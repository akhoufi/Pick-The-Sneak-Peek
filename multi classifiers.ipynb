{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk import *\n",
    "from sklearn import tree\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def pickle_file(filename, obj):\n",
    "    with open('dumps/' + filename, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def unpickle_file(filename):\n",
    "    with open('dumps/' + filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def print_classification_report(true, pred):\n",
    "    print(classification_report(true, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "# Remove punctuation, stopword and then stemmering\n",
    "    stop = set(stopwords.words(\"english\"))\n",
    "    stemmer = stem.PorterStemmer()\n",
    "    punctuation = set(string.punctuation)\n",
    "\n",
    "    doc = [stemmer.stem(word) for word in nltk.word_tokenize(text) if (word not in punctuation) and (word not in stop)]\n",
    "\n",
    "    doc = ' '.join(w for w in doc)\n",
    "    return doc\n",
    "\n",
    "data_train = pd.read_csv('data_train.csv', encoding='utf-8')\n",
    "\n",
    "data_train[\"Summary\"] = data_train[\"Summary\"].apply(preprocess)\n",
    "\n",
    "summaries_train = data_train['Summary'].as_matrix()\n",
    "\n",
    "ydf = data_train.drop('Summary', axis = 1)\n",
    "ydf = ydf.drop(ydf.columns[0], axis = 1)\n",
    "ydf = ydf.drop(ydf.columns[0], axis = 1)\n",
    "ydf = ydf.as_matrix()\n",
    "\n",
    "tfidfVect = TfidfVectorizer()\n",
    "tfidf = tfidfVect.fit_transform(summaries_train)\n",
    "\n",
    "pickle_file('tfidf.dat', tfidf)\n",
    "pickle_file('tfidf_vocab.dat', tfidfVect.vocabulary_)\n",
    "pickle_file('ydf.dat', ydf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vocab = TfidfVectorizer(decode_error=\"replace\",vocabulary=unpickle_file('tfidf_vocab.dat'))\n",
    "tfidf_train = unpickle_file('tfidf.dat')\n",
    "ydf = unpickle_file('ydf.dat')\n",
    "X_train = tfidf_train\n",
    "y_train = ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_linear_svc(features_train, labels_train):\n",
    "    print (\"Training linear SVC\")\n",
    "    clf = LinearSVC(C=1, dual=True, class_weight='balanced')\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_randomForest(features_train, labels_train):\n",
    "    print (\"Training random forest\")\n",
    "    clf = RandomForestClassifier(n_estimators=70, max_depth=70)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_decisionTree(features_train, labels_train):\n",
    "    print (\"Training decision tree\")\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_adaboost_decision_tree(features_train, labels_train):\n",
    "    print (\"Training adaboost decision tree\")\n",
    "    clf = AdaBoostClassifier( tree.DecisionTreeClassifier(max_depth=5),\n",
    "                              n_estimators=600,\n",
    "                              learning_rate=1)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_SGD_l1(features_train, labels_train):\n",
    "    print (\"Training SGD l1\")\n",
    "    clf = SGDClassifier(alpha=.0001, n_iter=50, penalty=\"l1\")\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "                        \n",
    "def train_SGD_l2(features_train, labels_train):\n",
    "    print (\"Training SGD l2\")\n",
    "    clf = SGDClassifier(alpha=.0001, n_iter=50, penalty=\"l2\")\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_SGD_elasticnet(features_train, labels_train):\n",
    "    print (\"Training SGD elascticnet\")\n",
    "    clf = SGDClassifier(alpha=.0001, n_iter=50, penalty=\"elasticnet\")\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_PassiveAggressiveClassifier(features_train, labels_train):\n",
    "    print (\"Training PassiveAggressiveClassifier\")\n",
    "    clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_RidgeClassifier(features_train, labels_train):\n",
    "    print (\"Training RidgeClassifier\")\n",
    "    clf = RidgeClassifier(tol=1e-2, solver=\"sag\")\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_KNeighborsClassifier(features_train, labels_train):\n",
    "    print (\"Training KNeighborsClassifier\")\n",
    "    clf = KNeighborsClassifier(n_neighbors=10)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_MultinomialNB(features_train, labels_train):\n",
    "    print (\"Training MultinomialNB\")\n",
    "    clf = MultinomialNB(alpha=.01)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_BernoulliNB(features_train, labels_train):\n",
    "    print (\"Training BernoulliNB\")\n",
    "    clf = BernoulliNB(alpha=.01)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_MLP(features_train, labels_train):\n",
    "    print (\"Training MLP\")\n",
    "    clf = MLPClassifier(random_state=0, max_iter=400)\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "\n",
    "def train_NearestCentroid(features_train, labels_train):\n",
    "    print (\"Training NearestCentroid\")\n",
    "    clf = NearestCentroid()\n",
    "    clf = OneVsRestClassifier(clf).fit(features_train, labels_train)\n",
    "    return clf\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv', encoding='utf-8')\n",
    "\n",
    "data_test[\"Summary\"] = data_test[\"Summary\"].apply(preprocess)\n",
    "\n",
    "summaries_test = data_test['Summary'].as_matrix()\n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "tfidf_test = transformer.fit_transform(tfidf_vocab.fit_transform(summaries_test))\n",
    "pickle_file('tfidf_test.dat', tfidf)\n",
    "X_test = tfidf_test\n",
    "\n",
    "\n",
    "ydf_test = pd.read_csv('labels_test.csv', encoding='utf-8')\n",
    "ydf_test = ydf_test.drop(ydf_test.columns[0], axis = 1)\n",
    "ydf_test = ydf_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.71      0.73     11088\n",
      "          1       0.55      0.50      0.53      3786\n",
      "          2       0.52      0.46      0.49      3435\n",
      "          3       0.70      0.63      0.67      1376\n",
      "          4       0.51      0.44      0.47      2825\n",
      "          5       0.46      0.31      0.37      1227\n",
      "          6       0.39      0.28      0.33      1519\n",
      "          7       0.37      0.25      0.29      1374\n",
      "          8       0.36      0.25      0.30      1171\n",
      "          9       0.47      0.36      0.41      3759\n",
      "         10       0.73      0.54      0.62      1313\n",
      "         11       0.64      0.33      0.43       359\n",
      "         12       0.56      0.46      0.51      3883\n",
      "         13       0.67      0.43      0.52       868\n",
      "         14       0.78      0.49      0.60       612\n",
      "         15       0.57      0.47      0.51      1790\n",
      "\n",
      "avg / total       0.59      0.50      0.54     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_classifier_linear = train_linear_svc(X_train, y_train)\n",
    "pickle_file('svm_classifier_linear', svm_classifier_linear)\n",
    "#svm_classifier_linear = unpickle_file('svm_classifier_linear')\n",
    "labels_pred = svm_classifier_linear.predict(X_test)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training random forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.88      0.78     11088\n",
      "          1       0.82      0.04      0.08      3786\n",
      "          2       0.78      0.01      0.02      3435\n",
      "          3       0.91      0.04      0.08      1376\n",
      "          4       1.00      0.01      0.01      2825\n",
      "          5       1.00      0.00      0.00      1227\n",
      "          6       1.00      0.00      0.00      1519\n",
      "          7       0.00      0.00      0.00      1374\n",
      "          8       0.00      0.00      0.00      1171\n",
      "          9       0.67      0.00      0.00      3759\n",
      "         10       0.93      0.06      0.12      1313\n",
      "         11       1.00      0.01      0.03       359\n",
      "         12       0.81      0.01      0.02      3883\n",
      "         13       1.00      0.01      0.01       868\n",
      "         14       0.95      0.06      0.11       612\n",
      "         15       0.97      0.02      0.04      1790\n",
      "\n",
      "avg / total       0.76      0.26      0.24     40385\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "random_forest = train_randomForest(X_train, y_train)\n",
    "pickle_file('random_forest', random_forest)\n",
    "labels_pred = random_forest.predict(X_test)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training decision tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.69      0.67     11088\n",
      "          1       0.45      0.36      0.40      3786\n",
      "          2       0.38      0.31      0.34      3435\n",
      "          3       0.45      0.41      0.43      1376\n",
      "          4       0.41      0.33      0.37      2825\n",
      "          5       0.31      0.23      0.26      1227\n",
      "          6       0.23      0.17      0.19      1519\n",
      "          7       0.20      0.13      0.16      1374\n",
      "          8       0.20      0.13      0.16      1171\n",
      "          9       0.36      0.20      0.26      3759\n",
      "         10       0.53      0.50      0.52      1313\n",
      "         11       0.36      0.27      0.31       359\n",
      "         12       0.43      0.28      0.34      3883\n",
      "         13       0.44      0.34      0.38       868\n",
      "         14       0.50      0.51      0.50       612\n",
      "         15       0.34      0.30      0.32      1790\n",
      "\n",
      "avg / total       0.46      0.40      0.42     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = train_decisionTree(X_train, y_train)\n",
    "pickle_file('decision_tree', decision_tree)\n",
    "labels_pred = decision_tree.predict(X_test)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training adaboost decision tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.73      0.71     11088\n",
      "          1       0.53      0.36      0.43      3786\n",
      "          2       0.51      0.32      0.39      3435\n",
      "          3       0.71      0.38      0.50      1376\n",
      "          4       0.56      0.29      0.39      2825\n",
      "          5       0.47      0.11      0.18      1227\n",
      "          6       0.46      0.12      0.18      1519\n",
      "          7       0.48      0.09      0.15      1374\n",
      "          8       0.45      0.09      0.16      1171\n",
      "          9       0.48      0.19      0.27      3759\n",
      "         10       0.78      0.39      0.52      1313\n",
      "         11       0.73      0.19      0.31       359\n",
      "         12       0.56      0.32      0.40      3883\n",
      "         13       0.65      0.28      0.39       868\n",
      "         14       0.82      0.40      0.54       612\n",
      "         15       0.60      0.24      0.34      1790\n",
      "\n",
      "avg / total       0.59      0.39      0.45     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_decision_tree = train_adaboost_decision_tree(X_train, y_train)\n",
    "labels_pred = adaboost_decision_tree.predict(X_test)\n",
    "pickle_file('adaboost_decision_tree', adaboost_decision_tree)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD l1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.88      0.78     11088\n",
      "          1       0.74      0.13      0.23      3786\n",
      "          2       0.72      0.05      0.10      3435\n",
      "          3       0.87      0.28      0.43      1376\n",
      "          4       0.70      0.11      0.19      2825\n",
      "          5       0.56      0.01      0.02      1227\n",
      "          6       0.25      0.00      0.00      1519\n",
      "          7       0.33      0.00      0.00      1374\n",
      "          8       0.61      0.02      0.04      1171\n",
      "          9       0.60      0.02      0.05      3759\n",
      "         10       0.85      0.28      0.42      1313\n",
      "         11       0.84      0.06      0.11       359\n",
      "         12       0.73      0.10      0.17      3883\n",
      "         13       0.77      0.14      0.23       868\n",
      "         14       0.81      0.21      0.33       612\n",
      "         15       0.80      0.12      0.21      1790\n",
      "\n",
      "avg / total       0.68      0.31      0.33     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD_l1 = train_SGD_l1(X_train, y_train)\n",
    "labels_pred = SGD_l1.predict(X_test)\n",
    "pickle_file('SGD_l1.dat', SGD_l1)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD l2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.82      0.78     11088\n",
      "          1       0.74      0.24      0.37      3786\n",
      "          2       0.75      0.16      0.27      3435\n",
      "          3       0.90      0.41      0.56      1376\n",
      "          4       0.73      0.17      0.27      2825\n",
      "          5       0.78      0.06      0.10      1227\n",
      "          6       0.69      0.03      0.06      1519\n",
      "          7       0.48      0.01      0.01      1374\n",
      "          8       0.77      0.03      0.05      1171\n",
      "          9       0.69      0.07      0.13      3759\n",
      "         10       0.90      0.33      0.48      1313\n",
      "         11       0.89      0.11      0.19       359\n",
      "         12       0.74      0.19      0.30      3883\n",
      "         13       0.87      0.24      0.38       868\n",
      "         14       0.89      0.25      0.39       612\n",
      "         15       0.83      0.21      0.34      1790\n",
      "\n",
      "avg / total       0.75      0.35      0.40     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD_l2 = train_SGD_l2(X_train, y_train)\n",
    "labels_pred = SGD_l2.predict(X_test)\n",
    "pickle_file('SGD_l2', SGD_l2)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD elascticnet\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78     11088\n",
      "          1       0.75      0.19      0.30      3786\n",
      "          2       0.76      0.10      0.17      3435\n",
      "          3       0.90      0.35      0.50      1376\n",
      "          4       0.74      0.13      0.23      2825\n",
      "          5       0.78      0.01      0.03      1227\n",
      "          6       0.76      0.01      0.02      1519\n",
      "          7       1.00      0.00      0.00      1374\n",
      "          8       0.77      0.02      0.04      1171\n",
      "          9       0.69      0.04      0.08      3759\n",
      "         10       0.89      0.28      0.43      1313\n",
      "         11       0.90      0.08      0.14       359\n",
      "         12       0.76      0.15      0.25      3883\n",
      "         13       0.86      0.18      0.30       868\n",
      "         14       0.87      0.18      0.29       612\n",
      "         15       0.85      0.18      0.29      1790\n",
      "\n",
      "avg / total       0.77      0.32      0.36     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGD_elasticnet = train_SGD_elasticnet(X_train, y_train)\n",
    "labels_pred = SGD_elasticnet.predict(X_test)\n",
    "pickle_file('SGD_elasticnet', SGD_elasticnet)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD PassiveAggressiveClassifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.70      0.70     11088\n",
      "          1       0.52      0.41      0.46      3786\n",
      "          2       0.50      0.37      0.42      3435\n",
      "          3       0.73      0.59      0.65      1376\n",
      "          4       0.48      0.36      0.41      2825\n",
      "          5       0.48      0.25      0.33      1227\n",
      "          6       0.38      0.21      0.27      1519\n",
      "          7       0.36      0.19      0.25      1374\n",
      "          8       0.34      0.18      0.23      1171\n",
      "          9       0.42      0.30      0.35      3759\n",
      "         10       0.76      0.49      0.60      1313\n",
      "         11       0.70      0.31      0.43       359\n",
      "         12       0.51      0.38      0.44      3883\n",
      "         13       0.67      0.37      0.48       868\n",
      "         14       0.79      0.47      0.59       612\n",
      "         15       0.57      0.40      0.47      1790\n",
      "\n",
      "avg / total       0.57      0.45      0.50     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PassiveAggressiveClassifier = train_PassiveAggressiveClassifier(X_train, y_train)\n",
    "labels_pred = PassiveAggressiveClassifier.predict(X_test)\n",
    "pickle_file('PassiveAggressiveClassifier', PassiveAggressiveClassifier)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD RidgeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriel\\Anaconda3\\envs\\py2\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:311: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.79      0.76     11088\n",
      "          1       0.70      0.26      0.38      3786\n",
      "          2       0.68      0.22      0.33      3435\n",
      "          3       0.89      0.40      0.55      1376\n",
      "          4       0.69      0.20      0.31      2825\n",
      "          5       0.69      0.10      0.18      1227\n",
      "          6       0.59      0.06      0.11      1519\n",
      "          7       0.49      0.04      0.07      1374\n",
      "          8       0.65      0.05      0.08      1171\n",
      "          9       0.64      0.14      0.23      3759\n",
      "         10       0.90      0.33      0.48      1313\n",
      "         11       0.88      0.13      0.22       359\n",
      "         12       0.69      0.23      0.34      3883\n",
      "         13       0.82      0.24      0.38       868\n",
      "         14       0.89      0.26      0.40       612\n",
      "         15       0.81      0.24      0.37      1790\n",
      "\n",
      "avg / total       0.71      0.36      0.43     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RidgeClassifier = train_RidgeClassifier(X_train, y_train)\n",
    "labels_pred = RidgeClassifier.predict(X_test)\n",
    "pickle_file('RidgeClassifier', RidgeClassifier)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SGD KNeighborsClassifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.70      0.68     11088\n",
      "          1       0.60      0.10      0.17      3786\n",
      "          2       0.60      0.09      0.15      3435\n",
      "          3       0.82      0.35      0.49      1376\n",
      "          4       0.55      0.05      0.09      2825\n",
      "          5       0.60      0.02      0.04      1227\n",
      "          6       0.56      0.02      0.04      1519\n",
      "          7       0.48      0.02      0.03      1374\n",
      "          8       0.63      0.03      0.06      1171\n",
      "          9       0.38      0.07      0.11      3759\n",
      "         10       0.87      0.14      0.24      1313\n",
      "         11       0.78      0.06      0.11       359\n",
      "         12       0.48      0.07      0.12      3883\n",
      "         13       0.76      0.10      0.17       868\n",
      "         14       0.77      0.07      0.12       612\n",
      "         15       0.72      0.22      0.33      1790\n",
      "\n",
      "avg / total       0.61      0.26      0.30     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "KNeighborsClassifier = train_KNeighborsClassifier(X_train, y_train)\n",
    "labels_pred = KNeighborsClassifier.predict(X_test)\n",
    "pickle_file('KNeighborsClassifier', KNeighborsClassifier)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.79      0.75     11088\n",
      "          1       0.57      0.33      0.42      3786\n",
      "          2       0.57      0.33      0.42      3435\n",
      "          3       0.81      0.52      0.63      1376\n",
      "          4       0.53      0.17      0.26      2825\n",
      "          5       0.57      0.19      0.28      1227\n",
      "          6       0.34      0.12      0.17      1519\n",
      "          7       0.32      0.12      0.17      1374\n",
      "          8       0.44      0.06      0.11      1171\n",
      "          9       0.45      0.18      0.26      3759\n",
      "         10       0.74      0.39      0.51      1313\n",
      "         11       0.70      0.11      0.19       359\n",
      "         12       0.55      0.23      0.32      3883\n",
      "         13       0.70      0.30      0.42       868\n",
      "         14       0.84      0.25      0.39       612\n",
      "         15       0.69      0.36      0.47      1790\n",
      "\n",
      "avg / total       0.60      0.40      0.45     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MultinomialNB = train_MultinomialNB(X_train, y_train)\n",
    "labels_pred = MultinomialNB.predict(X_test)\n",
    "pickle_file('MultinomialNB', MultinomialNB)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     11088\n",
      "          1       0.55      0.48      0.51      3786\n",
      "          2       0.47      0.52      0.49      3435\n",
      "          3       0.64      0.58      0.61      1376\n",
      "          4       0.58      0.43      0.49      2825\n",
      "          5       0.31      0.46      0.37      1227\n",
      "          6       0.36      0.28      0.32      1519\n",
      "          7       0.33      0.28      0.30      1374\n",
      "          8       0.38      0.27      0.32      1171\n",
      "          9       0.48      0.54      0.51      3759\n",
      "         10       0.45      0.54      0.49      1313\n",
      "         11       0.84      0.30      0.45       359\n",
      "         12       0.48      0.45      0.46      3883\n",
      "         13       0.64      0.48      0.55       868\n",
      "         14       0.32      0.64      0.43       612\n",
      "         15       0.55      0.46      0.50      1790\n",
      "\n",
      "avg / total       0.55      0.57      0.55     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB = train_BernoulliNB(X_train, y_train)\n",
    "labels_pred = BernoulliNB.predict(X_test)\n",
    "pickle_file('BernoulliNB', BernoulliNB)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72     11088\n",
      "          1       0.54      0.41      0.47      3786\n",
      "          2       0.52      0.37      0.43      3435\n",
      "          3       0.75      0.60      0.66      1376\n",
      "          4       0.49      0.34      0.40      2825\n",
      "          5       0.52      0.23      0.32      1227\n",
      "          6       0.39      0.18      0.25      1519\n",
      "          7       0.36      0.16      0.22      1374\n",
      "          8       0.41      0.16      0.24      1171\n",
      "          9       0.45      0.30      0.36      3759\n",
      "         10       0.77      0.48      0.59      1313\n",
      "         11       0.69      0.23      0.35       359\n",
      "         12       0.54      0.38      0.45      3883\n",
      "         13       0.70      0.37      0.48       868\n",
      "         14       0.83      0.49      0.62       612\n",
      "         15       0.62      0.41      0.49      1790\n",
      "\n",
      "avg / total       0.59      0.45      0.50     40385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MLP = train_MLP(X_train, y_train)\n",
    "labels_pred = MLP.predict(X_test)\n",
    "pickle_file('MLP', MLP)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NearestCentroid\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'OneVsRestClassifier' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-757ae5fc8e8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNearestCentroid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_NearestCentroid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlabels_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestCentroid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpickle_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NearestCentroid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNearestCentroid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint_classification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mydf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-086e3382bc43>\u001b[0m in \u001b[0;36mtrain_NearestCentroid\u001b[0;34m(features_train, labels_train)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_NearestCentroid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Training NearestCentroid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNearestCentroid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'OneVsRestClassifier' object is not callable"
     ]
    }
   ],
   "source": [
    "NearestCentroid = train_NearestCentroid(X_train, y_train)\n",
    "labels_pred = NearestCentroid.predict(X_test)\n",
    "pickle_file('NearestCentroid', NearestCentroid)\n",
    "print_classification_report(ydf_test, labels_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
